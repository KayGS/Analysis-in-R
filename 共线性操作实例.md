````R
library(car)
library(carData)
library(MASS)
library(glmnet)
library(pls)
````

`data <- read.csv(file.choose())`

# 查看数据结构
````R
str(data)
summary(data)
````

# 预处理数据：将类别变量转换为数值变量
````R
data$gender <- as.numeric(factor(data$gender))
data$preferred_category <- as.numeric(factor(data$preferred_category))
# 排除id列
data <- data[ , !(names(data) %in% c("id"))]
````

# 构建线性回归模型
````R
model <- lm(last_purchase_amount ~ ., data = data)
````

# 计算VIF
````R
vif_values <- vif(model)
print(vif_values)
````

# 使用岭回归分析共线性
````R
X <- model.matrix(last_purchase_amount ~ ., data = data)[,-1]
Y <- data$last_purchase_amount
ridge_model <- lm.ridge(last_purchase_amount ~ ., data = data, lambda = 0.1)
print(ridge_model)
````
> 岭回归（Ridge Regression）是一种正则化方法，它通过在回归模型中引入一个惩罚项来减小回归系数的大小，从而减少共线性对模型的影响。惩罚项的大小由参数 λ（lambda）控制。
>  
>  在R中，lm.ridge函数的输出包括以下关键结果：
>  
>  lambda：岭回归中的正则化参数。选择合适的lambda值可以在减少共线性的同时保持模型的预测能力。
>  coef：回归系数。在岭回归中，这些系数通常会比普通最小二乘法的系数更小，因为正则化项限制了系数的大小。
>  GCV（Generalized Cross-Validation）：广义交叉验证误差，用于选择最佳的lambda值。较小的GCV值表示模型的预测能力较强。
>  解释岭回归结果的步骤：
>  
>  查看和选择合适的λ值（通常通过交叉验证或GCV选择）。
> 检查回归系数是否合理，是否显著减小了共线性带来的影响。
>  解释：
> 
>  λ值为0.1，表示适中的正则化强度。
>  所有系数都比普通线性回归中的系数更小，这表明正则化项有效地减少了共线性对系数的不良影响。
>  GCV值为0.032，较小的GCV值表示模型具有较强的预测能力。


# 使用主成分分析（PCA）分析共线性
````R
pca_model <- prcomp(X, scale. = TRUE)
pca_r<- pca_model$rotation
summary(pca_model)
````
> 主成分分析（PCA）结果解释
> 主成分分析（PCA）是一种降维技术，通过将原始变量转换成一组不相关的新变量（主成分）来减少数据的维度。这些新变量是原始变量的线性组合，并且按解释的方差大小排序。
>  
>  在R中，prcomp函数的输出包括以下关键结果：
> 
> sdev：每个主成分的标准偏差。
>  rotation：主成分的载荷矩阵，表示每个主成分是如何由原始变量线性组合而来的。
>  center和scale：用于中心化和标准化的均值和标准差。
>  x：数据在主成分上的投影（即主成分得分）。
>  解释PCA结果的步骤：
>  
> 解释方差比例：summary(pca_model) 输出的方差比例（Proportion of Variance）和累积方差比例（Cumulative Proportion）表示每个主成分解释的总方差的比例。通常，我们关注前几个主成分，这些主成分解释了大部分方差。
>  主成分载荷（Loadings）：rotation 矩阵显示每个原始变量在每个主成分中的贡献。载荷较大的变量对相应主成分的贡献较大。
>  选择重要的主成分：根据方差比例和累积方差比例，选择能够解释大部分方差的主成分，通常是解释累积方差超过80%或90%的主成分。
>  解释：
>  
>  主成分PC1解释了45.23%的总方差，PC2解释了12.13%的总方差，前两个主成分累积解释了57.36%的总方差。
>  根据累积方差比例，前几个主成分（如PC1和PC2）解释了大部分的总方差，可以认为它们是数据的重要特征。
>  查看rotation矩阵，可以确定哪些原始变量在这些主成分中占有较大的权重，从而理解这些主成分的含义。


# 使用主成分回归（PCR）分析共线性
````R
pcr_model <- pcr(last_purchase_amount ~ ., data = data, scale = TRUE, validation = "CV")
````
>  1. scale 参数
>  scale = TRUE 的意思是对数据进行标准化处理，即将每个变量的均值减去并除以其标准差。这一步骤对于PCA和PCR非常重要，因为它确保了所有变量都在同一个尺度上，从而不会因为量纲的差异而对主成分的计算产生不公平的影响。
>  
>  具体解释：
>  
>  标准化处理：将每个变量的值减去其均值，并除以其标准差。
>  目的：确保不同变量的量纲一致，避免某些变量由于量纲较大而在PCA中占据主导地位。
>  2. validation 参数
>  validation = "CV" 的意思是使用交叉验证（Cross-Validation）来评估模型的性能。交叉验证是一种评估模型泛化能力的方法，通过将数据集划分为多个子集，多次训练模型并在未参与训练的子集上测试模型，从而得到更可靠的模型性能评估。
>  
>  具体解释：
>  
>  交叉验证（Cross-Validation）：一种将数据集分成多个子集的技术，通过在多个训练-测试分割中评估模型性能。
>  目的：评估模型的泛化能力，即在未见过的数据上的表现，防止过拟合。
>  常见的交叉验证方法：
>  
>  k折交叉验证（k-fold Cross-Validation）：将数据集分成k个子集，进行k次训练和测试，每次使用一个子集作为测试集，剩余子集作为训练集。
>  留一法交叉验证（Leave-One-Out Cross-Validation, LOOCV）：每次使用一个数据点作为测试集，剩余数据点作为训练集，进行n次训练和测试（n为数据点总数）。

# 输出PCR模型结果
````R
summary(pcr_model)
````
>  Data: 	X dimension: 1000 7 
>  Y dimension: 1000 1
>  Fit method: svdpc
>  Number of components considered: 7
>  
>  VALIDATION: RMSEP
>  Cross-validated using 10 random segments.
>  (Intercept)  1 comps  2 comps  3 comps  4 comps  5 comps  6 comps  7 comps
>  CV           295.9    296.3    296.1    296.0    295.6    295.3    295.4    295.2
>  adjCV        295.9    296.3    296.0    295.5    295.4    295.2    295.3    295.1
>  
>  TRAINING: % variance explained
>  1 comps  2 comps  3 comps  4 comps  5 comps  6 comps  7 comps
>  X                     15.59960   30.629    45.16   59.533   73.662   87.165  100.000
>  last_purchase_amount   0.08301    0.387     1.04    1.086    1.194    1.199    1.509

> 解释主成分回归（PCR）结果
>  
>  从你的PCR模型结果中，我们可以获得以下信息：
>  
>  #### 1. 数据维度
>  - **X dimension: 1000 7**：表示自变量矩阵有1000个观测值和7个变量。
>  - **Y dimension: 1000 1**：表示因变量向量有1000个观测值。
>  
>  #### 2. 拟合方法
>  - **Fit method: svdpc**：表示使用奇异值分解（SVD）来进行主成分回归。
>  
>  #### 3. 考虑的主成分数量
>  - **Number of components considered: 7**：模型中最多考虑了7个主成分。
>  
>  #### 4. 验证结果：RMSEP（均方根误差）
>  - **VALIDATION: RMSEP**：通过10折交叉验证评估模型的均方根误差（Root Mean Square Error of Prediction, RMSEP）。
>  
>  表格中的数据：
>  - **CV** 和 **adjCV**：分别表示未经调整和调整后的交叉验证结果。每列表示包含相应数量主成分时的RMSEP值。
>  
>  | Components | (Intercept) | 1 comps | 2 comps | 3 comps | 4 comps | 5 comps | 6 comps | 7 comps |
>    |------------|--------------|---------|---------|---------|---------|---------|---------|---------|
>    | CV         | 295.9        | 296.3   | 296.1   | 296.0   | 295.6   | 295.3   | 295.4   | 295.2   |
>    | adjCV      | 295.9        | 296.3   | 296.0   | 295.5   | 295.4   | 295.2   | 295.3   | 295.1   |
>    
>    解释：
>  - **RMSEP值**：表示不同数量主成分时的预测误差。可以看出，当主成分数量增加时，RMSEP值逐渐减小，但变化不大。
>  - **选择合适的主成分数量**：通常选择RMSEP值最小或开始趋于平稳时的主成分数量。在此例中，RMSEP值在第5个主成分后趋于平稳，因此可以考虑选择5个主成分。
>  
>  #### 5. 训练结果：解释的方差比例
>  - **TRAINING: % variance explained**：表示不同数量的主成分解释的自变量和因变量的方差比例。
>  
>  | Components | 1 comps | 2 comps | 3 comps | 4 comps | 5 comps | 6 comps | 7 comps |
>    |------------|---------|---------|---------|---------|---------|---------|---------|
>    | X          | 15.5996 | 30.629  | 45.16   | 59.533  | 73.662  | 87.165  | 100.000 |
>    | last_purchase_amount | 0.08301 | 0.387   | 1.04    | 1.086   | 1.194   | 1.199   | 1.509   |
>    
>    解释：
>  - **自变量方差比例**：第1个主成分解释了自变量的15.60%的方差，前两个主成分解释了30.63%的方差，依此类推，所有7个主成分解释了100%的自变量方差。
>  - **因变量方差比例**：第1个主成分解释了因变量的0.083%的方差，前两个主成分解释了0.387%的方差，依此类推。
>  
>  ### 总结
>  
>  通过主成分回归分析，我们可以得出以下结论：
>  1. **RMSEP值**：在5个主成分后，RMSEP值趋于平稳，建议选择5个主成分来平衡模型复杂度和预测性能。
>  2. **解释的方差比例**：前5个主成分解释了大约73.66%的自变量方差，但对因变量的解释能力较低，这可能表明原始变量对因变量的解释能力有限，或者存在较高的噪声。
>  
>  ### 进一步步骤
>  
>  如果你需要进一步优化模型或解释结果，可以考虑以下步骤：
>  - **进一步数据预处理**：检查数据质量，处理异常值和缺失值，可能会提高模型性能。
>  - **特征工程**：创建更多有意义的特征，可能有助于提高模型的解释能力。
>  - **正则化方法**：如Lasso回归或Elastic Net回归，这些方法可以在减少共线性的同时选择重要特征。

# 绘制解释方差的图表
````R
validationplot(pcr_model, val.type = "MSEP")
````

>  PCA和线性回归：如果你只需要降维并进行回归分析，可以先进行PCA，然后使用主成分进行线性回归。
>  PCR：如果你需要解决共线性问题并进行回归分析，PCR是一个整合的方法，它包括了PCA的步骤，无需再单独进行PCA。
# 进行PCA
````R
pca_model <- prcomp(X, scale. = TRUE)
summary(pca_model)
````

# 提取主成分
````R
X_pca <- pca_model$x
````

# 将主成分数据合并为数据框，用于PCR
````R
pca_data <- data.frame(X_pca, Y)
````

# 进行PCR
````R
pcr_model <- pcr(Y ~ ., data = pca_data, scale = TRUE, validation = "CV")
````

# 输出PCR结果
````R
summary(pcr_model)
validationplot(pcr_model, val.type = "MSEP")
````
